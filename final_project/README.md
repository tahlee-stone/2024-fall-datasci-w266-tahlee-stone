
# Groundedness Classification for Hallucination Detection in LLMs

## Objective
This project fine-tunes a **cross-encoder classifier** to detect hallucinations in responses generated by large language models (LLMs). Specifically, it evaluates **groundedness**—the degree to which a model's output is faithful to a given context.

## Motivation
LLMs often generate fluent but inaccurate or fabricated content. Detecting ungrounded responses is crucial in high-stakes applications like banking, where factual consistency and reliability are essential.

## Approach
We cast hallucination detection as a **(query, context, response) classification** task. The project builds and fine-tunes a cross-encoder model to determine whether a response is grounded in the provided context.

### Key Components
- **Dataset**:
  - Created from synthetic or public US retail bank data.
  - Optionally generated from HaluEval-style JSONL using:
    ```bash
    python scripts/data_processing.py
    ```
    This expands 500 sampled rows into 1000 examples (grounded and hallucinated), saved as:
    ```
    data/halueval_groundedness_500x2_YYYYMMDD_HHMMSS.csv
    ```

- **Models**:
  - **Cross-Encoder**: Fine-tuned transformer that jointly embeds all inputs.
  - **Bi-Encoder Baseline**: SentenceTransformer model with cosine similarity.
  - **LLM Verifier**: Prompted GPT-based self-check classifier.
  - **AWS Bedrock Guardrail**: Off-the-shelf factuality evaluator.

## Why Cross-Encoder?
- **Richer representations**: Encodes all three inputs together to detect subtle inconsistencies.
- **Balanced performance**: Stronger than bi-encoders, faster and cheaper than full LLMs.

## Directory Structure
  ```bash
  groundedness_project/
  ├── data/ # Groundedness datasets (CSV/JSONL)
  ├── notebooks/ # Exploratory notebooks and evaluation
  ├── src/ # Cross-encoder training, evaluation logic
  ├── scripts/ # Data preprocessing and sampling tools
  ├── models/ # Saved checkpoints (if applicable)
  ├── results/ # Metrics, charts, tables
  └── README.md # Project overview (this file)
  ```

## Usage Instructions
1. **Preprocess dataset**:
   ```bash
   py scripts/run_data_prep.py --input data/qa_data.json --output data/halueval_groundedness.csv --sample_size 500

    ```

   
2. **Set up comparison models**:
    ```bash
    python src/groundedness_pipeline.py
     ```

 3. **Set up comparison models**:
    ```bash
    python src/bedrock_llm_evaluators.py
     ```

## Next Steps
Complete fine-tuning and log performance metrics
Evaluate against baselines and analyze failure cases
Visualize results for final report and presentation

